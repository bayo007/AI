{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.0.0-beta1\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequence\n",
    "from tensorflow.keras.layers import Dense,Input,GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Conv1D , MaxPooling2D, Embedding\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://lazyprogrammer.me/course_files/spam.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv', encoding ='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Unnamed: 2\",\"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['labels', 'data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create binary labels\n",
    "df['b_labels'] = df['labels'].map({'ham':0, 'spam':1})\n",
    "Y= df['b_labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split up the data\n",
    "df_train, df_test, Ytrain, Ytest = train_test_split(df['data'], Y, test_size= 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert sentences to sequences\n",
    "MAX_VOCAB_SIZE =20000 #most common words in english language has 3000 words, so 3000 will cover 95% of most texts\n",
    "tokenizer = Tokenizer(num_words = MAX_VOCAB_SIZE) #instantaite Tokenizer class with a max number of words\n",
    "tokenizer.fit_on_texts(df_train) #this is just like sklearn .fit and .transorm packages\n",
    "sequences_train= tokenizer.texts_to_sequences(df_train) #this is just like sklearn .fit and .transorm packages\n",
    "sequences_test= tokenizer.texts_to_sequences(df_test) #this is just like sklearn .fit and .transorm packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word -> integer mapping\n",
    "\n",
    "word2idx = tokenizer.word_index\n",
    "V = len(word2idx)\n",
    "print('Found %s unique Tokens.' % V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad sequence so that we get a N x T matrix\n",
    "data_train = pad_sequences(sequences_train)\n",
    "print('Shape of data train tensor:', data_train.shape)\n",
    "\n",
    "#get sequence length\n",
    "T= data_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pad_sequence(sequences_test, maxlen=T)\n",
    "print('Shape of data tet tensor:', data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model\n",
    "#we get to choose embedding dimensionally\n",
    "D = 20\n",
    "\n",
    "\n",
    "\n",
    "#Note we actually want te size of teh embedding to be (V+1) x D,\n",
    "#because the first index starts from 1 and not 0\n",
    "#thus , if the final index of teh embedding matrix is V,\n",
    "#then it actually must have size V +1\n",
    "\n",
    "i = Input(shape=(T,)) #number of time steps\n",
    "x = Embedding(V+1, D)(i) #number of input features, for 1D convolution we need T x D number fo time steps and number of features\n",
    "x = Conv1D(32,3, activation = 'relu')(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Conv1D(64, 3, activation='relu')(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Conv1D(128, 3, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile and fit\n",
    "model.compile(\n",
    "loss='binary_crossentropy',\n",
    "optimizer='adam',\n",
    "metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print('Training Model....')\n",
    "r= model.fit(\n",
    "data_train,\n",
    "Ytrain,\n",
    "epochs=10,\n",
    "validation_data=(data_test,Y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss per iteration\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy per iteration\n",
    "plt.plot(r.history['accuracy'], label='acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
